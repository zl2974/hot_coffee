---
title: "Hypothesis test"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(patchwork)
library(plotly)
library(leaflet)
library(ggplot2)
library(lubridate)

knitr::opts_chunk$set(
  fig.height = 6,
  fig.width = 8,
  message = F,
  echo = T,
  warning = F,
  cache = F
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  digits = 3
)

scale_colour_discrete = scale_colour_viridis_d

scale_fill_discrete = scale_fill_viridis_d


```

```{r load_data,echo = FALSE, message=FALSE,warning = FALSE}
cafe = read_csv(here::here("data/Sidewalk_Caf__Licenses_and_Applications_clean.csv"))

parking = read_csv(here::here("data/parking_vio2021_cleanv1.csv")) %>%
  filter(hour != 12.3, hour <= 24) %>%
  left_join(
    read_csv("./data/Parking_Violations_Issued_-_Fiscal_Year_2021.csv") %>%
      janitor::clean_names() %>%
      select(summons_number, violation_county)
  ) %>%
  mutate(
    borough =
      case_when(
        violation_county %in% c("BK", "K") ~ "Brooklyn",
        violation_county %in% c("MN", "NY") ~ "Manhattan",
        violation_county %in% c("Q", "QN") ~ "Queens",
        violation_county %in% c("BX") ~ "Bronx"
      ),
    borough = replace_na(borough, "Staten Island")
  )%>% 
  drop_na(address) %>% 
  filter(issue_date <= as.Date("2020-11-16"))

```


## Hypothesis test about fine amount

### Anova between fine amount and different boros

From data exploration, we have notice that the violation code varies among 
boroughs as well as the fine amount. We see from the table that the mean of 
fine amount in Queen is different from the Manhattan by 10$, and thus, we 
propose hypothesis that there's at least 1 pairs of boroughs' fine amount is 
different from others.


```{r,echo = FALSE, message=FALSE,warning = FALSE}
parking %>% 
  drop_na(fine_amount, borough)%>%
  select(borough, fine_amount)%>%
  group_by(borough) %>% 
  summarize(mean = mean(fine_amount),
            standard_error = sd(fine_amount)) %>% 
  knitr::kable(caption = "Fine Amount in borough")

```

To do that, we perform ANOVA test for multiple groups comparison. With:

$H_0$ : there's no difference of fine amount means between boroughs

$H_1$ : at least two fine amount means of boroughs are not equal

```{r,echo = FALSE, message=FALSE,warning = FALSE}
boro_amount = parking %>% 
  drop_na(fine_amount, borough)%>%
  select(borough, fine_amount)%>%
  group_by(borough) 

aov_boro_amount = aov(fine_amount ~factor(borough), data = boro_amount)
summary(aov_boro_amount)
Tukey_comp<-TukeyHSD(aov_boro_amount,conf.level = 0.99)
Tukey_comp$`factor(borough)` %>% knitr::kable(caption = "Turkey Test at 99% confidence Level")
```


As the ANOVA test result from above, we reject the Null at 99% confidence level 
and conclude that there's at least one borough's mean of fine amount is different from others.

To further investigate the difference between boroughs, we perform Tukey test for pairwise comparison. Notice that all paris are different from each other in
 the setting of our data. Given the large amount of data, according to the law 
 of large number, the estimate of mean fine amount close to the true mean of the
  fine amount in different borough. Under this setting, we have 99% confidence 
  that Manhattan have different mean of fine amount than other borough. So if 
  you unfortunately get a RISKY coffee, it is much burning than in other boroughs.


## Hypothesis test about violation counts


### Chi-Squared test between violation counts generated in each weekdays and different boroughs

From data exploration, we have noticed that the violation counts proportions in different weekdays among each boroughs are different.Thus, we assume there is no homogeneity in tickets counts proportions in each weekdays among boroughs. 


To verify that, we performed Chi-squared test for multiple groups comparison. With:

$H_0$ : the tickets proportion in weekdays among boroughs are equal.

$H_1$ : not all proportions are equal

```{r,echo = FALSE, message=FALSE,warning = FALSE}


day_order = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")

chisq_boro_day = 
  parking %>% 
  mutate(day_week = weekdays(issue_date),
         day_week = factor(day_week, levels = day_order)) %>% 
  arrange(day_week) %>% 
  count(borough, day_week) %>% 
  drop_na(day_week, borough) %>% 
  pivot_wider(names_from = day_week,
              values_from = n) %>% 
  subset(select = c(-borough)) %>% 
  data.matrix() 
 
rownames(chisq_boro_day) <- c("Bronx", "Brooklyn", "Manhattan", "Queens", "Staten Island")
 
chisq_boro_day%>% 
  knitr::kable(caption = "Test Result")

chisq.test(chisq_boro_day)

x_crit = qchisq(0.95,24)
x_crit   # x critical value
```

According to above chi-square test result,  We reject the null hypothesis and conclude that there's at least one borough's proportions of violation counts for week days is different from others at 0.05 significant level.  

###  Chi-Squared test between violation counts generated in each hour and different boroughs:

```{r,echo = FALSE, message=FALSE,warning = FALSE}
chisq_boro_hour = 
  parking %>% 
  filter(hour != 12.3) %>% 
  filter(hour < 24) %>% 
  count(borough, hour) %>% 
  drop_na(borough) %>% 
  pivot_wider(names_from = hour,
              values_from = n) %>% 
  subset(select = c(-borough)) %>% 
  data.matrix() 
 
rownames(chisq_boro_hour) <- c("Bronx", "Brooklyn", "Manhattan", "Queens", "Staten Island")
 
chisq_boro_hour %>% knitr::kable()

chisq.test(chisq_boro_hour)%>% 
  broom::tidy() %>% knitr::kable()

x_crit = qchisq(0.95,92)
x_crit   # x critical value
```

According to above chi-square test result,  We reject the null hypothesis and conclude that there's at least one borough's proportions of violation counts for 24 hours is different from others at 0.05 significant level.  

Sine 526.14 million square feet of office space existed in Manhattan in 2020. Manhattan’s office space is located in 3,830 commercial buildings in the major markets of Midtown, Midtown South, Lower Manhattan and Uptown [[Statistics](https://www.statista.com/statistics/605882/size-of-office-area-manhattan-by-submarket/)]. At any given time most of this office space is rented. Manhattan becomes the well deserved business center in NYC. Due to the unequal active status of commerce among boroughs and expensive costs of keeping a car in NYC, the active area of life and work for people who own a car concentrates upon Manhattan. This is one of reasonable explanations of chi-square test result. But this situation might be changed since the commercial areas tend to extend to other boroughs. Some data in the report shows that the Bronx office market and the Staten Island office market have seen increased investor interest over the past 10 years [[click here to get more detailed information](https://www.metro-manhattan.com/blog/market-report-a-look-at-nyc-office-sales-activity-from-2010-to-2020/)].


## Regression Exploration

The resulting data frame of `boro_daytime_violation` contains a single dataframe df with  2,231,935rows of data on 8 variables, the list below is our variables of interest:

  * `violation_number`. mean of violation
  * `month`. Issue month
  * `workday_weekend`. a factor variable: 1 represent workday(Monday to Friday), 0 represent weekend
  * `hour`. Time(hour) violation occurred.
  * `daytime`. a factor variable: 1 represent daytime(8am to 8pm), 0 represent night(8pm to 8am)
  * `street_name`. Street name of summons issued.
  * `vehicle_color`. Color of car written on summons.
  * `borough`. Borough of violation.
  
The data frame of `boro_daytime_violationln` contains an addtional variable:

 * `ln_violation`. logarithm transformation of mean of violation
 
```{r model_data, cache = T}
boro_daytime_violation = 
  parking %>%  
  mutate(
    daytime = if_else(hour %in% 8:20,"1","0"),
    day_week = weekdays(issue_date),
    workday_weekend = if_else(day_week %in% c("Monday", "Tuesday", "Wednesday","Thursday", "Friday"),"1","0"),
    month = lubridate::month(issue_date),
    month = forcats::fct_reorder(as.factor(month),month)
  ) %>% 
  drop_na(vehicle_color, street_name) %>% 
  group_by(borough,month,workday_weekend,daytime) %>%
  summarise(
    violation_number = mean(n()),
    street_name = street_name,
    vehicle_color = vehicle_color,
    street_name = street_name,
    month = month,
    hour = hour
  )
```



### Box-Cox Transformation
```{r cox, cache=T}
fit1 = 
  lm(violation_number ~ borough + factor(workday_weekend) + factor(daytime) + month, data = boro_daytime_violation)

MASS::boxcox(fit1)


```
we use box-cox method to determine transformation of y. Since λ is close to 0, logarithm transformation should apply to violation counts.

### MLR
```{r MLR, cache = T}
boro_daytime_violationln = boro_daytime_violation %>%
  mutate(ln_violation = log(violation_number, base = exp(1)))

fit1 = 
  lm(ln_violation ~ borough + factor(workday_weekend) + factor(daytime) + month, data = boro_daytime_violationln)

fit1 %>% 
  broom::tidy() %>% 
  knitr::kable(caption = "Linar Regression Result")
```

From above linear regression model, we could see that boroughs, month, workday/weekend, daytime/night are significant variables for violation counts prediction. These variabkes are  

$~$
When Bronx works as reference, the p values for "Brooklyn", "Manhattan", "Queens" are far away smaller than 0.05. This means boroughs has significant effect on violation counts prediction. Staten Island has negative estimate and very small p value because its very small violation counts by comparing to other boroughs.  

$~$

The NYC parking regulation:[free parking on major Legal Holidays and Sundays:](https://newyorkparkingticket.com/parking-rules-holidays-sundays/). This explain why p-value of “workday_weekend” is below 0.05. That means workday factor is significant. Comparing with weekend, there are more parking violation on workdays than weenend due to NYC free parking rules on Sunday.This result is corresponding with the Violation per Hour plot we made in [data exploration](https://zl2974.github.io/hot_coffee/data_exploration.html)  
$~$
The p vale of factor(daytime)1 is less than 0.05. It makes sense, since people more likely to go out and parking on the street on daytime than night. And parking seems to become a routine issue for commuters.  
$~$
The P value for each month is smaller than 2e^16. No matter which month to go out, there will be a significant risk of receiving a parking tickets. The police goes to work on the whole of the year. There might have another explanation for the significance of month. There might some months need to be pay more attention to. May, June, Junly and August are usually summer holiday for students all over the world. Due to that NYC is a tourist attraction, the number of tourists should be increased from May to August. Tourists who aren't familiar with the NYC parking rules may easily receive parking tickets.


### Model diagnosis
```{r model_su, cache = T}
summary(fit1)

set.seed(500)
sample_fit1 = 
  boro_daytime_violationln %>% 
  sample_n(5e+3, replace = TRUE)

sample_lm = lm(ln_violation ~ borough + factor(workday_weekend) + factor(daytime) + month, sample_fit1)

par(mfrow = c(2,2))
plot(sample_lm)
```

We can see that the residual vs fitted is not equally distributed around 0 horizontal line. In fact, there's a pattern in the residual, indicating that the model although have high goodness of fit, but violating normal assumption on the residual. As a matter of fact, our data follows poison distribution, and thus linear model wouldn't be appropriated for our model. When we doing regression, linear model will not be consider.