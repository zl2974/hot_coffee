---
title: "Report"
output: 
  html_document:
    code_fload : hide
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(patchwork)
library(plotly)
library(leaflet)
library(ggplot2)
library(lubridate)

knitr::opts_chunk$set(
  fig.height = 6,
  fig.width = 8,
  message = F,
  echo = T,
  warning = F,
  cache = F
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  digits = 3
)

scale_colour_discrete = scale_colour_viridis_d

scale_fill_discrete = scale_fill_viridis_d

```

```{r load_data,echo = F}
cafe = read_csv(here::here("data/Sidewalk_Caf__Licenses_and_Applications_clean.csv"))

parking = read_csv(
  here::here("data/parking_vio2021_cleanv1.csv")) %>% 
  filter(hour != 12.3) 

```

# Report{.tabset}

## Data Processing

\ We set NYC Open Data as primary data source, and required:

1. Open Parking and Camera Violations
1. Parking Violations Issued - Fiscal Year 2021
1. Sidewalk CafÃ© Licenses and Applications

from NYC Open Data.

\ With these data, we first clean all variable names and select target variables for comparison 
between data, as well as changing variable types to reflecting their actual value.
Then we focus on acquiring geometric information via available 
information in the datasets. We wrote a function to pull geometric information 
from [Geosearch](https://labs-geosearch-docs.netlify.app/). 
Third, we identified violation in a certain range of area, and nest them to the
 location we interested.
 
## data exploration

To get the most comprehesive understanding the distribution of violation tickets
 among NYC, we map all violation to a 3D surface.
 
```{r map,cache=T}
parking %>%
  select(long, lat, hour) %>%
  mutate(long = abs(long)) %>%
  drop_na() %>%
  with(., MASS::kde2d(lat, long)) %>%
  as_tibble() %>%
  plot_ly() %>%
  add_surface(x = ~ x, y = ~ y, z = ~ z) %>%
  layout(scene = list(
    yaixs = list(autorange = "reversed"),
    zaxis = list(
      range = c(0.1, 150),
      title = "",
      showline = FALSE,
      showticklabels = FALSE,
      showline = FALSE,
      showgrid = FALSE
    ),
    camera = list(eye = list(
      x = -1.25, y = 1.25, z = 1.25
    )),
    showlegend = FALSE
  ))

parking %>% 
  drop_na(borough) %>% 
  group_by(borough) %>% 
  summarise(ticket =
              n()/nrow(parking)) %>% 
  arrange(desc(ticket)) %>% 
  pivot_wider(
    names_from = borough,
    values_from = ticket
  ) %>% 
  knitr::kable()
```

\ We can see that most of the violation ticket issued is concentrated in Manhattan by a large margin, followed by Brooklyn at 23.2%. Staten Island has 
the least violation ticket issued.

\ Once we have the distribution of the issued, we exploring its characteristics.
Most of the issued ticket of 2020 by the latest data recording is centered at the 3rd quater, this very strange pattern in the normal time wouldn't come to a 
surprise at 2020, as NY didn't reopen until late May. Once it reopened, the violation 
issued increased exponentially.

```{r bar_by_month}
parking %>% 
  mutate(month = lubridate::month(issue_date),
         month = forcats::fct_reorder(as.factor(month),month)
         ) %>% 
  drop_na(month,borough) %>% 
  group_by(borough,month) %>% 
  summarize(tickets = n()) %>% 
  ungroup() %>%
  mutate(borough = forcats::fct_reorder(borough,tickets,sum)) %>% 
  ggplot(aes(x = month, y = tickets, fill = borough,group = borough)) + 
    geom_bar(stat = "identity",position = "dodge") +
    labs(
      x = 'Issuing Month',
      y = 'counts',
      title = 'The distribution of tickets quantities over month ')
```

\ Trend of violation tickets issued can be seen via .... As shown, Violation 
tickets mostly issued in the daytime. Two peaks are observed in the animation, 
which is 8 am and 13pm, representing 
`r parking %>% filter(hour==8) %>% nrow()*100/nrow(parking)`% and 
`r parking %>% filter(hour==13) %>% nrow()*100/nrow(parking)`% tickets issued 
of the day.

```{r hour_map,cache=T}
nyc =
  parking %>%
  drop_na(long, lat) %>%
  summarise(
    lon_max = max(long),
    lon_min = min(long),
    lat_max = max(lat),
    lat_min = min(lat)
  )

nyc =
  ggmap::get_map(location = c(
    right = pull(nyc, lon_max),
    left = pull(nyc, lon_min),
    top = pull(nyc, lat_max),
    bottom = pull(nyc, lat_min)
  ))

set.seed(1)
parking %>%
  filter(hour <= 24) %>%
  drop_na(borough,lat,long,hour) %>% 
  sample_n(1e+5) %>% 
  plot_ly()  %>% 
    add_markers(
    y = ~ lat,
    x = ~ long,
    alpha = 0.02,
    frame = ~ hour,
    mode = "marker",
    color = ~borough,
    colors = viridis::viridis(4,option = "C")
  ) %>%
  layout(
    images = list(
      source = raster2uri(nyc),
      xref = "x",
      yref = "y",
      y = 40.5,
      x = -74.3	,
      sizey = 0.4,
      sizex = 0.6,
      sizing = "stretch",
      xanchor = "left",
      yanchor = "bottom",
      opacity = 0.4,
      layer = "below"
    )
  )%>%
  animation_opts(transition = 0,frame = 24)
```

\ Group by borough, we seen that these trends vary. As in Manhattan, the peaks 
is similar to the global trend, but other boroughs have a earlier or no second 
peak. This might reflect the nature of most business center is located in Manhattan, and thus has a larger lunch break group.

```{r hour_borough, cache = T}
parking %>% 
  group_by(hour,borough) %>%
  drop_na(hour,borough) %>% 
  summarise(n = n()) %>% 
  plot_ly(x = ~hour, y = ~n, type = 'scatter',mode = 'line', color= ~ borough) %>%
  layout(
    title = 'Violations per Hour',
    xaxis = list(
      type = 'category',
      title = 'Hour',
      range = c(0, 23)),
    yaxis = list(
      title = 'Count of violations'))
```


# Cluster Analysis
\ Using the information gained from above, we agree that cluster analysis would 
help reflect some of relationship in the data. We use k-means distants to 
determines our clusters. To simplify our analysis but reserve the most information, we choose to limit our data to Viehical types to _PAS_ as passenger's vehical

```{r kmean, cache=T}
set.seed(1)
```

